---
title: "Revised Graphics Summarizing Shellfish Bacteria Data"
author: "Curtis C. Bohlen, Casco Bay Estuary Partnership."
date: "02/17/2021"
output:
  github_document:
    toc: true
    fig_width: 5
    fig_height: 4
---
<img
    src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
    style="position:absolute;top:10px;right:50px;" />

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center',
                      fig.width = 5, fig.height = 4,
                      collapse = TRUE, comment = "#>")
```

# Introduction
Exploratory analysis highlights the extreme skewness of the distribution of
bacteria data, both here with the shellfish-related data collected by DMR, and 
with the data related to recreational beaches, collected by towns, and managed
by DEP.

Here we present graphical summaries of the data, with an emphasis on reporting 
observed quantities that relate to regulatory thresholds, especially geometric 
means and 90th percentiles related to whether sites can be classified as
"Approved" for harvest.  

The motivation for this notebook came from comments from reviewers of our draft 
State of Casco Bay chapter that our rosy analysis of shellfish bacteria data 
held for geometric mean thresholds, but less so for the "p90" or 90th percentile 
thresholds.  That means we needed to find ways to depict both geometric mean 
and p90 values in at least some graphics.

# Relevant Standards
Growing Area Classification | Activity Allowed |	Geometric mean FC/100ml	| 90th Percentile (P90) FC/100ml
----------------------------|------------------|--------------------------|-------------------------------
Approved	               | Harvesting allowed	                                                      | ≤ 14	              | ≤ 31
Conditionally Approved	 | Harvesting allowed except during specified conditions	                  | ≤ 14 in open status	| ≤ 31 in open status
Restricted	             | Depuration harvesting or relay only	                                    | ≤ 88 and >15	      | ≤ 163 and >31
Conditionally Restricted |Depuration harvesting or relay allowed except during specified conditions	| ≤ 88 in open status	| ≤ 163 in open status
Prohibited	             | Aquaculture seed production only	                                        | >88	                |>163

# Load Libraries
```{r}
library(readr)
library(tidyverse)      # Loads another `select()`

library(emmeans)        # For marginal means
library(mgcv)           # For GAMs, here used principally for hierarchical models

library(CBEPgraphics)
load_cbep_fonts()
theme_set(theme_cbep())

library(LCensMeans)

```

# Load Data
## Main Data
```{r folders}
sibfldnm <- 'Derived_Data'
parent <- dirname(getwd())
sibling <- file.path(parent,sibfldnm)

dir.create(file.path(getwd(), 'figures'), showWarnings = FALSE)
```

```{r load_main_data)}
fl1<- "Shellfish data 2015 2018.csv"
path <- file.path(sibling, fl1)

coli_data <- read_csv(path, 
    col_types = cols(SDate = col_date(format = "%Y-%m-%d"), 
        SDateTime = col_datetime(format = "%Y-%m-%dT%H:%M:%SZ"), # Note Format!
        STime = col_time(format = "%H:%M:%S"))) %>%
  mutate_at(c(6:7), factor) %>%
  mutate(Class = factor(Class, levels = c( 'A', 'CA', 'CR',
                                           'R', 'P', 'X' ))) %>%
  mutate(Tide = factor(Tide, levels = c("L", "LF", "F", "HF",
                                        "H", "HE", "E", "LE"))) %>%
  mutate(DOY = as.numeric(format(SDate, format = '%j')),
         Month = as.numeric(format(SDate, format = '%m'))) %>%
  mutate(Month = factor(Month, levels = 1:12, labels = month.abb))
```

### Address Censored Data
We  calculate a estimated conditional mean to replace the (left) censored
values. The algorithm is not entirely appropriate, as it assumes lognormal
distribution, and our data are closer to Pareto-distributed.  Still, it handles
the non-detects on a more rational basis than the usual conventions.

Second, we calculate a version of the data where non-detects are replaced by
half the value of the detection limit.  However, we plan to use the LOG of
coliform counts in Gamma GLM models, which require response variables to be 
strictly positive. The most common Reporting Limit in these data is `RL == 2`. 
Half of that is 1.0, and `log(1.0) == 0`.  Consequently, we replace all 
values 1.0 with 1.1, as log(1.1) is positive, and thus can be modeled by
a suitable `gam()` model.

In this notebook, we do not use either of these altered versions of the data,
but instead rely only on results calculated assuming "non-detects" equal the 
reporting limit.  This (obviously) over estimates the true (unobserved) values
of the non-detects, but it is consistent, convenient, and transparent.

```{r}
coli_data <- coli_data %>%
  mutate(ColiVal_ml = sub_cmeans(ColiVal, LCFlag)) %>%
  mutate(ColiVal_hf = if_else(LCFlag, ColiVal/2, ColiVal),
         ColiVal_hf = if_else(ColiVal_hf == 1, 1.1, ColiVal_hf))
```

### Remove NAs
```{r}
coli_data <- coli_data %>%
  filter (! is.na(ColiVal))
```

### Remove Sites not in Region
We have some data that was selected for stations outside of Casco Bay. To be  
careful, we  remove sampling data for any site in th two adjacent Growing Areas,
"WH" and "WM".
```{r}
coli_data <- coli_data %>%
  filter(GROW_AREA != 'WH' & GROW_AREA != "WM") %>%
  mutate(GROW_AREA = fct_drop(GROW_AREA),
         Station = factor(Station))
```

## Weather Data
We simplify the weather data somewhat.
```{r load_weather_data}
sibfldnm    <- 'Original_Data'
parent      <- dirname(getwd())
sibling     <- file.path(parent,sibfldnm)

fn <- "Portland_Jetport_2015-2019.csv"
fpath <- file.path(sibling, fn)

weather_data <- read_csv(fpath, 
 col_types = cols(AWNDattr = col_skip(), 
        FMTM = col_skip(), FMTMattr = col_skip(), 
        PGTM = col_skip(), PGTMattr = col_skip(),
        PRCPattr = col_character(), SNOWattr = col_character(), 
        SNWD = col_skip(), SNWDattr = col_skip(),
        TAVG = col_number(), TAVGattr = col_character(), 
        TMIN = col_number(), TMINattr = col_character(), 
        TMAX = col_number(), TMAXattr = col_character(), 
        station = col_skip())) %>%
  select( ! starts_with('W')) %>%
  select(! ends_with('attr')) %>%
  rename(sdate = date,
         Precip=PRCP,
         MaxT = TMAX,
         MinT= TMIN,
         AvgT = TAVG,
         Snow = SNOW) %>%
  mutate(sdate = as.Date(sdate, format = '%m/%d/%Y'))
```

```{r}
weather_data <- weather_data %>%
  arrange(sdate) %>%
  
  select(sdate, Precip, AvgT, MaxT) %>%
  mutate(AvgT = AvgT / 10,
         MaxT = MaxT / 10,
         Precip = Precip / 10,
         Precip_d1 = dplyr::lag(Precip,1),
         Precip_d2 = dplyr::lag(Precip,2),
         Log1Precip    = log1p(Precip), 
         Log1Precip_d1 = log1p(Precip_d1),
         Log1Precip_d2 = log1p(Precip_d2),
         Log1Precip_2   = log1p(Precip_d1 + Precip_d2),
         Log1Precip_3   = log1p(Precip + Precip_d1 + Precip_d2))
```

### Incorporate Weather Data
```{r}
coli_data <- coli_data %>%
  left_join(weather_data, by = c('SDate' = 'sdate'))
```

## Summary Statistics Dataframe
We only work with the raw observed summary statistics here.
```{r}
sum_data <- coli_data %>%
  mutate(logcoli = log(ColiVal),
         logcoli2 = log(ColiVal_ml)) %>%
  group_by(Station) %>%
  summarize(mean1 = mean(ColiVal),
            median1 = median(ColiVal),
            iqr1 = IQR(ColiVal),
            p901 = quantile(ColiVal, 0.9),
            meanlog1 = mean(logcoli, na.rm = TRUE),
            sdlog1 = sd(logcoli, na.rm = TRUE),
            nlog1 = sum(! is.na(logcoli)),
            selog1 = sdlog1/sqrt(nlog1),
            gmean1 = exp(meanlog1),
            U_CI1 = exp(meanlog1 + 1.96 * selog1),
            L_CI1 = exp(meanlog1 - 1.96 * selog1)) %>%
  mutate(Station = fct_reorder(Station, gmean1))

```

# Critical levels (Reminder)
Geometric Mean include:  
$<=14$ and  $<= 88$  
and for the p90  
$< 31$ and $<= 16$   

#  Graphics for 238 Stations
## Bootstrap Confidence Interval Function
This is a general function, so needs to be passed log transformed data to
produce geometric means.  note that we can substitute another function for the 
mean to generate confidence intervals for other statistics, here the 90th
percentile.
```{r bootstrap_ci}
boot_one <- function (dat, fun = "mean", sz = 1000, width = 0.95) {
  
  low <- (1 - width)/2
  hi <- 1 - low

  vals <- numeric(sz)
  for (i in 1:sz) {
    vals[i] <- eval(call(fun, sample(dat, length(dat), replace = TRUE)))
  }
  return (quantile(vals, probs = c(low, hi)))
}
```

## Confidence Intervals for the Geometric Mean
We need to first calculate confidence intervals on a log scale, then build a
tibble and back transform them.
```{r}
gm_ci <- tapply(log(coli_data$ColiVal), coli_data$Station, boot_one)

# Convert to data frame (and then tibble...)
# This is convenient because as_tibble() drops the row names,
# which we want to keep.
gm_ci <- as.data.frame(do.call(rbind, gm_ci)) %>%
  rename(gm_lower1 = `2.5%`, gm_upper1 = `97.5%`) %>%
  rownames_to_column('Station')

# Back Transform
gm_ci <- gm_ci %>%
  mutate(gm_lower1 = exp(gm_lower1),
         gm_upper1 = exp(gm_upper1))
```


## Confidence Intervals for the 90th Percentile
Because we use `eval()` and call()` inside the `boot_one()` function, we need to
pass the function we want to bootstrap as a string. We can't pass in an
anonymous function.  The function `call()` assembles a call object
(unevaluated).  It's first argument must be a character string.  Then `eval()` 
evaluates the call, seeking the named function among function identifiers in
the current environment. 

All of that could be addressed with more advanced R programming, such as 
quoting function parameters or passing additional parameters to the call
object using R's ellipsis operator (`...`).  But for our current purpose, it is
far simpler to write a named function rather than revise and generalize the 
`boot_one()` function.  Besides, there are good packages to support
bootstrapping available.  If we needed a more capable bootstrap function, we 
would have used the `boot` package.
```{r}
p90 <- function(.x) quantile(.x, 0.9)
```

This takes a while to run because calculating percentiles is harder than 
calculating the mean.
```{r}
p90_ci <- tapply(coli_data$ColiVal, coli_data$Station,
               function(d) boot_one(d, 'p90'))

# Convert to data frame (and then tibble...) 
p90_ci <- as.data.frame(do.call(rbind, p90_ci)) %>%
  rename(p90_lower1 = `2.5%`, p90_upper1 = `97.5%`) %>%
  rownames_to_column('Station')
```

## Combining Results
We add results to the summary data. (Because this uses `left_join()`, rerunning
it without deleting the old versions will generate errors in later steps.)
```{r}
sum_data <-  sum_data %>% 
  left_join(gm_ci, by = 'Station') %>%
  left_join(p90_ci, by = 'Station') %>%
  mutate(Station = fct_reorder(Station, gmean1))

```

## Geometric Mean Plot
```{r station_bootstrap_gm_graphics, fig.height = 5, fig.width = 3.25}
plt <- ggplot(sum_data, aes(gmean1, Station)) + 
  geom_pointrange(aes(xmin = gm_lower1, xmax = gm_upper1),
                  color = cbep_colors()[6],
                  size = .2) +
  scale_x_log10(breaks = c(1,3,10,30, 100)) +
  
  xlab('Geometric Mean Fecal Coliforms\n(CFU / 100ml)') +

  ylab('Location') +
  
  geom_vline(xintercept = 14, lty = 2) +
  annotate('text', y = 30, x = 16, label = "14 CFU",
           size = 3, hjust = 0, angle = 270) +
  
  theme_cbep(base_size = 12) + 
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.line  = element_line(size = 0.5, 
                                  color = 'gray85'),
        panel.grid.major.x = element_line(size = 0.5, 
                                          color = 'gray85', 
                                          linetype = 2)) 
plt

ggsave('figures/stations_gm_bootstrap.pdf', device = cairo_pdf, 
       width = 3.25, height = 5)
```

## p90 Plot
```{r station_bootstrap_p90_graphics, fig.height = 5, fig.width = 3.25}
plt <- ggplot(sum_data, aes(p901, Station)) + 
  geom_pointrange(aes(xmin = p90_lower1, xmax = p90_upper1),
                  color = cbep_colors()[4],
                  size = .2) +
  scale_x_log10(breaks = c(1,3,10,30, 100)) +
  
  xlab('90th Percentile Fecal Coliforms\n(CFU / 100ml)') +

  ylab('Location') +
  
  geom_vline(xintercept = 31, lty = 2) +
  annotate('text', y = 30, x = 40, label = "31 CFU",
           size = 3, hjust = 0, angle = 270) +
  
  theme_cbep(base_size = 12) + 
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.line  = element_line(size = 0.5, 
                                  color = 'gray85'),
        panel.grid.major.x = element_line(size = 0.5, 
                                          color = 'gray85', 
                                          linetype = 2)) 
plt

ggsave('figures/stations_p90_bootstrap.pdf', device = cairo_pdf, 
       width = 3.25, height = 5)
```

# Frequency of Exceedences
```{r}
sum_data %>%
  summarize(exceeds_p90 = sum(p901 >= 31),
            exceeds_gm = sum(gmean1 > 14))
```

So just about 20% of sites fail the p90 "Accepted" threshold.

## Combined Plots
### Assemble Long Data
```{r}
long_dat <- sum_data %>%
  select(Station, gmean1, gm_lower1, gm_upper1, p901, p90_lower1, p90_upper1) %>%
  rename(gm_value = gmean1, p90_value = p901) %>%
  rename_with( ~sub('1', '', .x)) %>%
  pivot_longer(gm_value:p90_upper,
               names_to = c('parameter', 'type'), 
               names_sep = '_') %>%
  pivot_wider(c(Station, parameter), names_from = type, values_from = value) %>%
  mutate(parameter = factor(parameter, 
                            levels = c('gm', 'p90'), 
                            labels = c('Geometric Mean', '90th Percentile'))) %>%
  arrange(parameter, Station)
```

# Create Graphics
### Annotation Dataframe
We create a data frame that uses the same factor names, so we 
can direct different annotations to each panel

```{r}
annot_df <- tibble(parameter = factor(c(1,2), 
                                      labels = c('Geometric Mean',
                                                 '90th Percentile')),
                   threshold = c(14, 31),
                   txt = c('14 CFU', '31 CFU'),
                   adjust = c(3, 7.5),
                   adjust_no_bars = c(2, 4.5),
                   adjust_two = c(5, 12),
                   adjust_two_no_bars = c(3.5, 8))
```

## One  Panel
### With Error Bars
```{r station_bootstrap_one_graphics, fig.height = 5, fig.width = 4}
ggplot(long_dat, aes(value, Station)) + 

  geom_linerange(aes(xmin = lower, xmax = upper, color = parameter),
                 alpha = 0.5,
                 size = .1) +
  geom_point(aes(color = parameter), size = 0.5) + 
               
  scale_x_log10() +
  
  scale_color_manual(name = '', values = cbep_colors()[c(4,6)]) +
  scale_fill_manual(name = '', values = cbep_colors()[c(4,6)]) +

  xlab(expression(atop('Fecal Coliforms'),
                  '(CFU / 100ml)')) +

  ylab('Location') +
  expand_limits(y = 240) +  # this ensures the top dot is not cut off
  
  geom_vline(data = annot_df,
             mapping = aes(xintercept = threshold), 
             lty = 2, color = 'gray25') +
  geom_text(data = annot_df, y = 30, 
             mapping = aes(x = threshold + adjust, 
                           label = txt),
             size = 3, hjust = 0, angle = 270) +
  
  theme_cbep(base_size = 12) + 
  theme(legend.position = c(.7, .25),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.line  = element_line(size = 0.5, 
                                  color = 'gray85'),
        panel.grid.major.x = element_line(size = 0.5, 
                                          color = 'gray85', 
                                          linetype = 2)) +
  guides(color = guide_legend(override.aes = list(lty = 0, size = 2)))

ggsave('figures/stations_both_one.pdf', device = cairo_pdf, 
       width = 4, height = 5)
```

### Without Error Bars
```{r station_bootstrap_one_graphics_no_errors, fig.height = 5, fig.width = 4}
ggplot(long_dat, aes(value, Station)) + 
  
  geom_point(aes(color = parameter), size = 0.5) + 
  scale_x_log10() +
  
  scale_color_manual(name = '', values = cbep_colors()[c(4,6)]) +
  scale_fill_manual(name = '', values = cbep_colors()[c(4,6)]) +

  xlab(expression(atop('Fecal Coliforms'),
                  '(CFU / 100ml)')) +

  ylab('Location') +
  
  geom_vline(data = annot_df,
             mapping = aes(xintercept = threshold), 
             lty = 2, color = 'gray25') +
  geom_text(data = annot_df, y = 30, 
             mapping = aes(x = threshold + adjust_no_bars, 
                           label = txt),
             size = 3, hjust = 0, angle = 270) +
  
  theme_cbep(base_size = 12) + 
  theme(legend.position = c(.65, .25),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.line  = element_line(size = 0.5, 
                                  color = 'gray85'),
        panel.grid.major.x = element_line(size = 0.5, 
                                          color = 'gray85', 
                                          linetype = 2)) +
  guides(color = guide_legend(override.aes = list(lty = 0, size = 2)))

ggsave('figures/stations_both_one_no_err.pdf', device = cairo_pdf, 
       width = 4, height = 5)
```

## Two Panels
### With Error Bars
```{r station_bootstrap_combined_graphics, fig.height = 5, fig.width = 5}
ggplot(long_dat, aes(value, Station)) + 

  geom_linerange(aes(xmin = lower, xmax = upper),
                 color = 'gray75',
                 size = .1) +
  geom_point(aes(color = parameter), size = 0.5) + 
               
  scale_x_log10() +
  
  facet_wrap('parameter', nrow = 1) +
  scale_color_manual(values = cbep_colors()[c(4,6)]) +
  scale_fill_manual(values = cbep_colors()[c(4,6)]) +

  xlab(expression(atop('Fecal Coliforms'),
                  '(CFU / 100ml)')) +

  ylab('Location') +
  
  geom_vline(data = annot_df,
             mapping = aes(xintercept = threshold), 
             lty = 2, color = 'gray25') +
  geom_text(data = annot_df, y = 30, 
             mapping = aes(x = threshold + adjust_two, label = txt),
             size = 3, hjust = 0, angle = 270) +
  
  theme_cbep(base_size = 12) + 
  theme(legend.position = 'None',
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.line  = element_line(size = 0.5, 
                                  color = 'gray85'),
        panel.grid.major.x = element_line(size = 0.5, 
                                          color = 'gray85', 
                                          linetype = 2)) 

ggsave('figures/stations_both_two.pdf', device = cairo_pdf, 
       width = 5, height = 5)
```

### Without Error Bars
```{r station_bootstrap_combined_graphics_no_err, fig.height = 5, fig.width = 5}
ggplot(long_dat, aes(value, Station)) + 
  
  geom_point(aes(color = parameter), size = 0.5) + 
               
  scale_x_log10() +
  
  facet_wrap('parameter', nrow = 1) +
  scale_color_manual(values = cbep_colors()[c(4,6)]) +
  scale_fill_manual(values = cbep_colors()[c(4,6)]) +

  xlab(expression(atop('Fecal Coliforms'),
                  '(CFU / 100ml)')) +

  ylab('Location') +
  
  geom_vline(data = annot_df,
             mapping = aes(xintercept = threshold), 
             lty = 2, color = 'gray25') +
  geom_text(data = annot_df, y = 30, 
             mapping = aes(x = threshold + adjust_two_no_bars, label = txt),
             size = 3, hjust = 0, angle = 270) +
  
  theme_cbep(base_size = 12) + 
  theme(legend.position = 'None',
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.line  = element_line(size = 0.5, 
                                  color = 'gray85'),
        panel.grid.major.x = element_line(size = 0.5, 
                                          color = 'gray85', 
                                          linetype = 2)) 

ggsave('figures/stations_both_two_no_err.pdf', device = cairo_pdf, 
       width = 5, height = 5)
```

# Years Plot
Technically, this produces a plot with summary statistics calculated on the
log-transformed data. That means `stat_sumamry()` correctly displays the 
geometric mean.  However the `quantile()` function finds (and plots) the 90th
percentile of the LOG of the data, rather than the log transform of the 90th
percentile of the untransformed data.  Given the abundance of data here, that 
makes no practical difference in a graphic.
```{r time_plot}
plt <- ggplot(coli_data, aes(YEAR, ColiVal)) +
  geom_jitter(aes(color = LCFlag), alpha = 0.25, height = 0.05, width = 0.4) +
  ## We use the MEAN here because `stat_summary()` works on data after
  ## applying the transformation to the y axis, thus implicitly calculating the
  ## geometric mean.
  stat_summary(fun = mean, 
               fill = 'red', shape = 22) +
  stat_summary(fun = ~ quantile(.x, 0.9),
               fill = 'orange', shape = 23) +
  
  scale_color_manual(values = cbep_colors(), name = '',
                     labels = c('Observed', 'Below Detection')) +
  
  
  xlab('') +
  ylab('Fecal Coliforms\n(CFU / 100ml)') +

  scale_y_log10() +

  theme_cbep(base_size = 12) +
  theme(legend.position = "bottom") +
  
  guides(color = guide_legend(override.aes = list(alpha = c(0.5,0.75),
                                                  size = 3) ))
```

```{r years_add_ref_lines}
 plt +  
  geom_hline(yintercept = 14, lty = 2) +
  annotate('text', x = 2020, y = 17, 
           size = 3, hjust = .75, label = "14 CFU") +
  
  geom_hline(yintercept = 31, lty = 2) +
  annotate('text', x = 2020, y = 40, 
           size = 3, hjust = .75, label = "31 CFU") +
  scale_x_continuous(breaks = c(2015, 2017, 2019))

ggsave('figures/years.pdf', device = cairo_pdf, 
       width = 5, height = 4)

```
